{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec92dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3b1a2",
   "metadata": {},
   "source": [
    "## Tuning a CART's hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8239d90",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "- parameters: learned from data\n",
    " - CART example: split-point of a node, split-feature of a node, ...\n",
    "- hyperparameters: net learned from data, set prior to training\n",
    " - CART example: max_depth, min_samples_leaf, splitting criterion, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c721551",
   "metadata": {},
   "source": [
    "### What is hyperparameter tuning?\n",
    "- problem: search for a set of optimal hyperparameters for a learning algorithm\n",
    "- solution: find a set of optimal hyperparameters that results in an optimal model\n",
    "- optimal model: yields an optimal score\n",
    "- score: in sklearn defualts to accuracy (classification) and R_square (regression)\n",
    "- cross validation is used to estimate the generalization performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2701b",
   "metadata": {},
   "source": [
    "### Why tune hyperparameters?\n",
    "- in sklearn, a model's defualt hyperparameters are not optimal for all problems\n",
    "- hyperparameters should bbe tuned to obtain the best model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad6797",
   "metadata": {},
   "source": [
    "### Approaches to hyperparameter tuning\n",
    "- Grid Search\n",
    "- Random Search\n",
    "- Bayesian Optimization\n",
    "- Genetic Algorithms\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce163e",
   "metadata": {},
   "source": [
    "### Grid search cross validation\n",
    "- manually set a grid of discrete hyperparameter values\n",
    "- set a metric for scoring model performance\n",
    "- search exhaustively through the grid\n",
    "- for each set of hyperparamters, evaluate each model's CV score\n",
    "- the optimal hyperparameters are those of the model achieving the best CV score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7085fe0",
   "metadata": {},
   "source": [
    "### Inspecting the hyperparameters of a CART in sklearn (Breast-Cancer dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aebe0d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc = pd.read_csv('wbc.csv').drop('Unnamed: 32', axis=1)\n",
    "y = wbc['diagnosis']\n",
    "X = wbc.drop(['id', 'diagnosis'], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a473647e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': 1,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set seed to 1 for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt'\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "# Print out 'dt's hyperparameters\n",
    "dt.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7224b30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 4, 5, 6],\n",
       "                         'max_features': [0.2, 0.4, 0.6, 0.8],\n",
       "                         'min_samples_leaf': [0.04, 0.06, 0.08]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters 'params_dt'\n",
    "params_dt = {'max_depth': [3, 4, 5, 6], \n",
    "             'min_samples_leaf': [0.04, 0.06, 0.08], \n",
    "             'max_features': [0.2, 0.4, 0.6, 0.8]}\n",
    "\n",
    "# Instantiate a 10-fold CV grid search object 'grid_dt'\n",
    "grid_dt = GridSearchCV(estimator=dt, \n",
    "                       param_grid=params_dt, \n",
    "                       scoring='accuracy', \n",
    "                       cv=10, \n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Fit 'grid_dt' to the training data\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d4c4c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'max_features': 0.4, 'min_samples_leaf': 0.04}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best hyperparameters from 'grid_dt'\n",
    "grid_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64d454a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9406763285024156"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best CV score from 'grid_dt'\n",
    "grid_dt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90fc941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, max_features=0.4, min_samples_leaf=0.04,\n",
       "                       random_state=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best model from 'grid_dt'\n",
    "best_model = grid_dt.best_estimator_\n",
    "best_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4193e36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate test set accuracy\n",
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40858c47",
   "metadata": {},
   "source": [
    "### Exercise: Tree hyperparameters\n",
    "In the following exercises you'll revisit the Indian Liver Patient dataset which was introduced in a previous chapter.\n",
    "\n",
    "Your task is to tune the hyperparameters of a classification tree. Given that this dataset is imbalanced, you'll be using the ROC AUC score as a metric instead of accuracy.\n",
    "\n",
    "We have instantiated a DecisionTreeClassifier and assigned to dt with sklearn's default hyperparameters. You can inspect the hyperparameters of dt in your console.\n",
    "\n",
    "Which of the following is not a hyperparameter of dt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16aa461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "liver = pd.read_csv('indian_liver_patient.csv')\n",
    "liver.dropna(axis=0, inplace=True)\n",
    "liver['Is_male'] = liver['Gender'].astype('category').cat.codes\n",
    "X = liver.drop(['Dataset', 'Gender'] , axis=1)\n",
    "y = liver['Dataset']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2337d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': 1,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set seed to 1 for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt'\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "# Print out 'dt's hyperparameters\n",
    "dt.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6fb83d",
   "metadata": {},
   "source": [
    "### Exercise: Set the tree's hyperparameter grid\n",
    "In this exercise, you'll manually set the grid of hyperparameters that will be used to tune the classification tree dt and find the optimal classifier in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52df969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params_dt\n",
    "params_dt = {'max_depth': [2, 3, 4], \n",
    "             'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6eef69",
   "metadata": {},
   "source": [
    "### Exercise: Search for the optimal tree\n",
    "In this exercise, you'll perform grid search using 5-fold cross validation to find dt's optimal hyperparameters. Note that because grid search is an exhaustive process, it may take a lot time to train the model. Here you'll only be instantiating the GridSearchCV object without fitting it to the training set. As discussed in the video, you can train such an object similar to any scikit-learn estimator by using the .fit() method:\n",
    "\n",
    "grid_object.fit(X_train, y_train)\n",
    "\n",
    "An untuned classification tree dt as well as the dictionary params_dt that you defined in the previous exercise are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ab0393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Fit 'grid_dt' to the training data\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b62225",
   "metadata": {},
   "source": [
    "Awesome! As we said earlier, we will fit the model to the training data for you and in the next exercise you will compute the test set ROC AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900749e",
   "metadata": {},
   "source": [
    "### Exercise: Evaluate the optimal tree\n",
    "In this exercise, you'll evaluate the test set ROC AUC score of grid_dt's optimal model.\n",
    "\n",
    "In order to do so, you will first determine the probability of obtaining the positive label for each test set observation. You can use the methodpredict_proba() of an sklearn classifier to compute a 2D array containing the probabilities of the negative and positive class-labels respectively along columns.\n",
    "\n",
    "The dataset is already loaded and processed for you (numerical features are standardized); it is split into 80% train and 20% test. X_test, y_test are available in your workspace. In addition, we have also loaded the trained GridSearchCV object grid_dt that you instantiated in the previous exercise. Note that grid_dt was trained as follows:\n",
    "\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93535622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.731\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score from sklearn.metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5086323",
   "metadata": {},
   "source": [
    "## Tuning an RF's Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d59c6",
   "metadata": {},
   "source": [
    "### Random Forests Hyperparameters\n",
    "- CART hyperparameters\n",
    "- number of estimators\n",
    "- bootstrap\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0fb4cb",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning is expensive\n",
    "- computationally expensive\n",
    "- sometimes leads to very slight improvement\n",
    "- so, weight the impact of tuning on the whole project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0371e8ed",
   "metadata": {},
   "source": [
    "### Inspecting RF hyperparameters in sklearn (auto dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc72675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('auto.csv')\n",
    "auto['origin'] = auto['origin'].astype('category')\n",
    "dummies = pd.get_dummies(auto['origin'], prefix='origin')\n",
    "auto = pd.concat([auto, dummies], axis=1)\n",
    "\n",
    "X = auto.drop(['mpg', 'origin'], axis=1)\n",
    "y = auto['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4df634b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Instantiate a random forests regressor 'rf'\n",
    "rf = RandomForestRegressor(random_state= SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1fcb6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect rf's hyperparameters\n",
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68feaade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a grid of hyperparameter 'params_rf'\n",
    "params_rf = {'n_estimators': [300, 400, 500], \n",
    "             'max_depth': [4, 6, 8], \n",
    "             'min_samples_leaf': [0.1, 0.2], \n",
    "             'max_features': ['log2', 'sqrt']}\n",
    "\n",
    "# Instantiate 'grid_rf'\n",
    "grid_rf = GridSearchCV(estimator=rf, \n",
    "                       param_grid=params_rf, \n",
    "                       cv=3, \n",
    "                       scoring='neg_mean_squared_error', \n",
    "                       verbose=1, \n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21975884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_depth': [4, 6, 8],\n",
       "                         'max_features': ['log2', 'sqrt'],\n",
       "                         'min_samples_leaf': [0.1, 0.2],\n",
       "                         'n_estimators': [300, 400, 500]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit 'grid_rf' to the training set\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e680f2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 0.1,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the best hyperparameters from 'grid_rf'\n",
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b96f6ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=4, max_features='log2', min_samples_leaf=0.1,\n",
       "                      n_estimators=500, random_state=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the best model from 'grid_rf'\n",
    "best_model = grid_rf.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57177dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.18834338, 1.23605306, 1.4672004 , 1.30955372, 1.23204304])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddf420e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41163064876435845"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the test set RMSE\n",
    "MSE(y_test, y_pred)**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b27d66",
   "metadata": {},
   "source": [
    "### Exercise Random forests hyperparameters\n",
    "In the following exercises, you'll be revisiting the Bike Sharing Demand dataset that was introduced in a previous chapter. Recall that your task is to predict the bike rental demand using historical weather data from the Capital Bikeshare program in Washington, D.C.. For this purpose, you'll be tuning the hyperparameters of a Random Forests regressor.\n",
    "\n",
    "We have instantiated a RandomForestRegressor called rf using sklearn's default hyperparameters. You can inspect the hyperparameters of rf in your console.\n",
    "\n",
    "Which of the following is not a hyperparameter of rf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "657f0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('bikes.csv')\n",
    "y = bikes['cnt']\n",
    "X = bikes.drop('cnt', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f0526f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Instantiate a random forests regressor 'rf'\n",
    "rf = RandomForestRegressor(random_state= SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c61290b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect rf's hyperparameters\n",
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920347f3",
   "metadata": {},
   "source": [
    "### Exercise: Set the hyperparameter grid of RF\n",
    "In this exercise, you'll manually set the grid of hyperparameters that will be used to tune rf's hyperparameters and find the optimal regressor. For this purpose, you will be constructing a grid of hyperparameters and tune the number of estimators, the maximum number of features used when splitting each node and the minimum number of samples (or fraction) per leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc8c846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameter 'params_rf'\n",
    "params_rf = {'n_estimators': [100, 350, 500], \n",
    "             'min_samples_leaf': [2, 10, 30], \n",
    "             'max_features': ['log2', 'auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c060c6",
   "metadata": {},
   "source": [
    "### Exercise: Search for the optimal forest\n",
    "In this exercise, you'll perform grid search using 3-fold cross validation to find rf's optimal hyperparameters. To evaluate each model in the grid, you'll be using the negative mean squared error metric.\n",
    "\n",
    "Note that because grid search is an exhaustive search process, it may take a lot time to train the model. Here you'll only be instantiating the GridSearchCV object without fitting it to the training set. As discussed in the video, you can train such an object similar to any scikit-learn estimator by using the .fit() method:\n",
    "\n",
    "grid_object.fit(X_train, y_train)\n",
    "\n",
    "The untuned random forests regressor model rf as well as the dictionary params_rf that you defined in the previous exercise are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "198af18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 10, 30],\n",
       "                         'n_estimators': [100, 350, 500]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Fit 'grid_rf' to the training set\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0197959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'min_samples_leaf': 2, 'n_estimators': 100}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the best hyperparameters from 'grid_rf'\n",
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce97b96",
   "metadata": {},
   "source": [
    "### Exercise: Evaluate the optimal forest\n",
    "In this last exercise of the course, you'll evaluate the test set RMSE of grid_rf's optimal model.\n",
    "\n",
    "The dataset is already loaded and processed for you and is split into 80% train and 20% test. In your environment are available X_test, y_test and the function mean_squared_error from sklearn.metrics under the alias MSE. In addition, we have also loaded the trained GridSearchCV object grid_rf that you instantiated in the previous exercise. Note that grid_rf was trained as follows:\n",
    "\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e1b065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 51.779\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef4d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
