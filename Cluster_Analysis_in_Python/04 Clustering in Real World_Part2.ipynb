{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e4c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7827af09",
   "metadata": {},
   "source": [
    "## Document clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64dba4",
   "metadata": {},
   "source": [
    "### Document clustering: concepts\n",
    "- 1. Clean data before processing\n",
    "- 2. Determine the importance of the terms in a document(in TF-IDF matrix)\n",
    "- 3. Cluster the TF-IDF matrix\n",
    "- 4. Find top terms, documents in each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221dc61",
   "metadata": {},
   "source": [
    "### Clean and tokenize data\n",
    "- Convert text into smaller parts called tokens, clean data for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b153d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re  # regular expressions\n",
    "\n",
    "def remove_noise(text, stop_words = []):\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        token = re.sub('[^A-Za-z0-9]+', '', token)\n",
    "        if len(token) > 1 and token.lower() not in stop_words:\n",
    "            # Get lowercase\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af41f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'is',\n",
       " 'lovely',\n",
       " 'weather',\n",
       " 'we',\n",
       " 'are',\n",
       " 'having',\n",
       " '.',\n",
       " 'I',\n",
       " 'hope',\n",
       " 'the',\n",
       " 'weather',\n",
       " 'continues',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('It is lovely weather we are having. I hope the weather continues.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4a0f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'is',\n",
       " 'lovely',\n",
       " 'weather',\n",
       " 'we',\n",
       " 'are',\n",
       " 'having',\n",
       " 'hope',\n",
       " 'the',\n",
       " 'weather',\n",
       " 'continues']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_noise(\"It is lovely weather we are having. I hope the weather continues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17365a",
   "metadata": {},
   "source": [
    "### TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "- A weighted measure: evaluate how important a word  is to a document in a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb625d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = pd.read_csv('movies_plot.csv')['Plot'].loc[:249].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78e293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, \n",
    "                                   max_features=50, \n",
    "                                   min_df=0.2, \n",
    "                                   tokenizer=remove_noise)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a52483",
   "metadata": {},
   "source": [
    "### Clustering with sparse matrix\n",
    "- kmeans( in scipy does not support sparse matricse\n",
    "- Use .todense() to convert to a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e138385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans\n",
    "\n",
    "num_clusters=3\n",
    "cluster_centers, distortion = kmeans(tfidf_matrix.todense(), num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf757eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03199333, 0.03800253, 0.03905884, 0.04780701, 0.15927658,\n",
       "        0.08286124, 0.14366909, 0.10332187, 0.01572662, 0.06112195,\n",
       "        0.04432267, 0.01627148, 0.0612348 , 0.16220105, 0.03320014,\n",
       "        0.08915877, 0.1312196 , 0.12051358, 0.02581344, 0.02069035,\n",
       "        0.06471153, 0.04109723, 0.06502353, 0.03929313, 0.04106087,\n",
       "        0.05931895, 0.0856839 , 0.04183711, 0.03581026, 0.02019313,\n",
       "        0.09768303, 0.05684122, 0.05990943, 0.04036268, 0.0065288 ,\n",
       "        0.06716669, 0.09616371, 0.07169883, 0.02882143, 0.08292705,\n",
       "        0.05855747, 0.0482609 , 0.0807424 , 0.06684079, 0.06749194,\n",
       "        0.03200596, 0.0364663 , 0.05917189, 0.13646209, 0.02485002],\n",
       "       [0.06669829, 0.10953079, 0.04895786, 0.04969485, 0.11803865,\n",
       "        0.10019863, 0.15929194, 0.12475225, 0.07653305, 0.08340628,\n",
       "        0.05981812, 0.05802609, 0.14886519, 0.18307346, 0.04583243,\n",
       "        0.05107095, 0.17268784, 0.11298278, 0.05027139, 0.06399587,\n",
       "        0.1086991 , 0.06914847, 0.10724338, 0.23702478, 0.06039553,\n",
       "        0.10653747, 0.11694187, 0.04554314, 0.0747798 , 0.06195411,\n",
       "        0.16178911, 0.07687716, 0.11443879, 0.08400349, 0.04285363,\n",
       "        0.27479667, 0.08496311, 0.06830646, 0.07595409, 0.15359699,\n",
       "        0.05594388, 0.0599375 , 0.09045357, 0.08324401, 0.1240339 ,\n",
       "        0.06835594, 0.07738898, 0.07042521, 0.12310745, 0.06332132],\n",
       "       [0.06471937, 0.07543792, 0.04567577, 0.02511065, 0.06743245,\n",
       "        0.05580145, 0.11636257, 0.08553787, 0.04819704, 0.0486278 ,\n",
       "        0.04186483, 0.0233652 , 0.12470257, 0.1171902 , 0.0457334 ,\n",
       "        0.04226472, 0.11797279, 0.08904986, 0.0558437 , 0.039241  ,\n",
       "        0.10411612, 0.0340955 , 0.50610616, 0.15101288, 0.0250935 ,\n",
       "        0.05956457, 0.08448353, 0.06545457, 0.07092895, 0.03665099,\n",
       "        0.10222565, 0.04089416, 0.07355254, 0.33871562, 0.0518063 ,\n",
       "        0.17780388, 0.0773557 , 0.0455958 , 0.0391782 , 0.08167913,\n",
       "        0.03050831, 0.02867875, 0.04481226, 0.05384801, 0.09835008,\n",
       "        0.04463147, 0.0354866 , 0.05543711, 0.10069112, 0.05176963]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c3dab16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_centers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5bb85",
   "metadata": {},
   "source": [
    "### Top terms per cluster\n",
    "- Cluster centers: lists with a size equal to the number of terms\n",
    "- Each value in the cluster center is its importance\n",
    "- Create a dictionary and print top terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc0fc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'after', 'all', 'also', 'an', 'are', 'as', 'at', 'back', 'be', 'been', 'before', 'but', 'by', 'can', 'father', 'for', 'from', 'goes', 'had', 'has', 'have', 'her', 'him', 'himself', 'into', 'it', 'new', 'not', 'off', 'on', 'one', 'out', 'she', 'tells', 'that', 'their', 'them', 'then', 'they', 'this', 'two', 'up', 'was', 'when', 'where', 'which', 'while', 'who', 'will']\n"
     ]
    }
   ],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2543fe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['by', 'an', 'as']\n",
      "['that', 'him', 'by']\n",
      "['her', 'she', 'that']\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_clusters):\n",
    "    center_terms = dict(zip(terms, list(cluster_centers[i])))\n",
    "    sorted_terms = sorted(center_terms, key=center_terms.get, reverse=True)\n",
    "    print(sorted_terms[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d9704",
   "metadata": {},
   "source": [
    "### More considerations\n",
    "- Work with hyperlinks, emoticons, etc\n",
    "- Normalize words (run, ran, running --> run)\n",
    "- .todense() may not work with large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec63e2e0",
   "metadata": {},
   "source": [
    "### Exercise: TF-IDF of movie plots\n",
    "Let us use the plots of randomly selected movies to perform document clustering on. Before performing clustering on documents, they need to be cleaned of any unwanted noise (such as special characters and stop words) and converted into a sparse matrix through TF-IDF of the documents.\n",
    "\n",
    "Use the TfidfVectorizer class to perform the TF-IDF of movie plots stored in the list plots. The remove_noise() function is available to use as a tokenizer in the TfidfVectorizer class. The .fit_transform() method fits the data into the TfidfVectorizer objects and then generates the TF-IDF sparse matrix.\n",
    "\n",
    "Note: It takes a few seconds to run the .fit_transform() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5db98095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer class from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=0.1, \n",
    "                                   max_df=0.75, \n",
    "                                   max_features=50, \n",
    "                                   tokenizer=remove_noise)\n",
    "\n",
    "# Use the .fit_transform() method on the list plots\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46a372",
   "metadata": {},
   "source": [
    "That is correct! You have successfully created the sparse matrix. Let us now perform clustering on the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ffd9e",
   "metadata": {},
   "source": [
    "### Exercise: Top terms in movie clusters\n",
    "Now that you have created a sparse matrix, generate cluster centers and print the top three terms in each cluster. Use the .todense() method to convert the sparse matrix, tfidf_matrix to a normal matrix for the kmeans() function to process. Then, use the .get_feature_names() method to get a list of terms in the tfidf_vectorizer object. The zip() function in Python joins two lists.\n",
    "\n",
    "The tfidf_vectorizer object and sparse matrix, tfidf_matrix, from the previous have been retained in this exercise. kmeans has been imported from SciPy.\n",
    "\n",
    "With a higher number of data points, the clusters formed would be defined more clearly. However, this requires some computational power, making it difficult to accomplish in an exercise here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be8676f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['her', 'she', 'him']\n",
      "['him', 'they', 'an']\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 2\n",
    "\n",
    "# Generate cluster centers through the kmeans function\n",
    "cluster_centers, distortion = kmeans(tfidf_matrix.todense(), num_clusters)\n",
    "\n",
    "# Generate terms from the tfidf_vectorizer object\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    # Sort the terms and print top 3 terms\n",
    "    center_terms = dict(zip(terms, list(cluster_centers[i])))\n",
    "    sorted_terms = sorted(center_terms, key=center_terms.get, reverse=True)\n",
    "    print(sorted_terms[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d6d74",
   "metadata": {},
   "source": [
    "~~You are correct! Notice positive, warm words in the first cluster and words referring to action in the second cluster.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb156bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
